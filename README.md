# NotebookLocal - Intelligent Vault Assistant

A **context-aware AI assistant** for Obsidian vaults that understands your notes and responds naturally. Built with a **service-oriented architecture** combining FastAPI intelligence backend with Obsidian plugin frontend, featuring real-time document processing and natural language interaction.

**Core Philosophy**: Transform knowledge work from command-driven to conversation-driven through intelligent document understanding and natural language processing.

## ğŸ§  Philosophy: Context-Aware Intelligence

Transform your vault interaction from command-driven to conversation-driven:

- **Natural Language**: "What did I conclude about this topic?" instead of `/search topic`
- **Intelligent Context**: System automatically builds relevance-ranked context pyramids
- **Smart @Mentions**: `@file1.md,file2.md` or `@folder/` for precise targeting
- **Intent Understanding**: System detects whether you want to UNDERSTAND, NAVIGATE, TRANSFORM, SYNTHESIZE, or MAINTAIN

## ğŸ—ï¸ Intelligence Architecture

```mermaid
graph TB
    subgraph "ğŸ§  Intelligence System"
        UI[Natural Language Input]
        ID[Intent Detector]
        CR[Capability Router]
        CE[Context Engine]
        
        subgraph "5 Core Capabilities"
            UE[UNDERSTAND Engine]
            NE[NAVIGATE Engine] 
            TE[TRANSFORM Engine]
            SE[SYNTHESIZE Engine]
            ME[MAINTAIN Engine]
        end
    end
    
    subgraph "ğŸ“š Knowledge Base"
        PG[(PostgreSQL)]
        VDB[Vector Store]
        FILES[Vault Files]
    end
    
    UI --> ID
    ID --> CR
    CR --> CE
    CE --> PG
    CE --> VDB
    CR --> UE
    CR --> NE
    CR --> TE
    CR --> SE
    CR --> ME
    
    FILES --> PG
```

## ğŸ¯ Core Capabilities

### ğŸ¤” **UNDERSTAND**
Answer questions using your vault as ground truth
```
What did I conclude about this topic?
Explain the key concepts from my research
@meeting-notes.md What were the action items?
```

### ğŸ—ºï¸ **NAVIGATE** 
Find and discover content across your vault
```
Find everything about API design
Show me notes related to machine learning
@research/ What patterns do you see?
```

### âœ¨ **TRANSFORM**
Intelligently edit and improve your content
```
Make this note clearer and more structured
Improve the flow of this argument
@draft.md Rewrite this for a technical audience
```

### ğŸ”„ **SYNTHESIZE**
Extract insights and patterns across multiple notes
```
Summarize my research findings this month
What themes emerge from my project notes?
@notes1.md,notes2.md,notes3.md Compare these approaches
```

### ğŸ”§ **MAINTAIN**
Keep your vault healthy and organized
```
Check for broken links in my vault
Find duplicate content across notes
Suggest better organization for my files
```

## ğŸ® Natural Usage Examples

### **Instead of commands, just ask naturally:**

**Old way (commands):**
```
/rag-enable
/rag-scope selected  
@meeting-notes.md @project-docs/
/search "key insights"
```

**New way (natural + @mentions):**
```
@meeting-notes.md @project-docs/ What are the key insights from our recent discussions?
```

**The system automatically:**
1. **Understands** your intent (SYNTHESIZE capability)
2. **Gathers** relevant context from mentioned files + related content
3. **Processes** using the appropriate engine
4. **Executes** and provides insights with source citations

## ğŸ“ Service Architecture Overview

```
26th-summer-NotebookLocal/
â”œâ”€â”€ README.md                          # Service overview & philosophy
â”œâ”€â”€ PIPELINE.md                        # Complete technical pipeline
â”œâ”€â”€ inference-server/                  # ğŸ Python FastAPI Backend Service
â”‚   â”œâ”€â”€ src/intelligence/             # ğŸ§  Intelligence Processing Core
â”‚   â”‚   â”œâ”€â”€ context_engine.py         # Context pyramid builder
â”‚   â”‚   â”œâ”€â”€ intent_detector.py        # Natural language â†’ intent routing
â”‚   â”‚   â”œâ”€â”€ capability_router.py      # Route to capability engines
â”‚   â”‚   â””â”€â”€ intelligence_service.py   # Main orchestration service
â”‚   â”œâ”€â”€ src/services/                 # ğŸ”§ Business Logic Services
â”‚   â”‚   â”œâ”€â”€ document_processing_service.py  # Document workflow orchestration
â”‚   â”‚   â”œâ”€â”€ processing_models.py      # Data models & types
â”‚   â”‚   â””â”€â”€ background_processor.py   # Async processing worker
â”‚   â”œâ”€â”€ src/workflows/                # ğŸ“‹ Processing Workflows
â”‚   â”‚   â””â”€â”€ document_workflow.py      # LangGraph document pipeline
â”‚   â”œâ”€â”€ src/processors/              # âš™ï¸  Content Processors
â”‚   â”‚   â”œâ”€â”€ pdf_processor.py          # PDF text/image extraction
â”‚   â”‚   â”œâ”€â”€ image_processor.py        # Vision model descriptions
â”‚   â”‚   â”œâ”€â”€ text_processor.py         # Chunking & tokenization
â”‚   â”‚   â””â”€â”€ embedder.py               # Vector embedding generation
â”‚   â”œâ”€â”€ src/storage/                 # ğŸ’¾ Data Storage Layer
â”‚   â”‚   â”œâ”€â”€ hybrid_store.py          # PostgreSQL + Vector hybrid
â”‚   â”‚   â””â”€â”€ vector_store.py          # Weaviate/vector operations
â”‚   â”œâ”€â”€ src/vault/                   # ğŸ“ File Management Services
â”‚   â”‚   â”œâ”€â”€ file_manager.py          # File metadata management
â”‚   â”‚   â”œâ”€â”€ file_watcher.py          # Real-time change detection
â”‚   â”‚   â””â”€â”€ file_queue_manager.py    # Processing queue management
â”‚   â”œâ”€â”€ api/                         # ğŸŒ API Gateway Layer
â”‚   â”‚   â”œâ”€â”€ intelligence_routes.py   # Intelligence endpoints
â”‚   â”‚   â”œâ”€â”€ document_routes.py       # Document processing API
â”‚   â”‚   â”œâ”€â”€ vault_routes.py         # File management API
â”‚   â”‚   â””â”€â”€ main.py                 # FastAPI application
â”‚   â””â”€â”€ src/llm/core/               # ğŸ¤– LLM Integration Layer
â”‚       â”œâ”€â”€ router.py               # Multi-model routing
â”‚       â””â”€â”€ providers/              # Model provider implementations
â””â”€â”€ notebook-local/                 # ğŸ§© Obsidian Plugin (React Components)
    â”œâ”€â”€ src/intelligence/           # ğŸ§  Plugin Intelligence Controller
    â”‚   â””â”€â”€ IntelligenceController.ts # Natural language processing
    â”œâ”€â”€ src/components/             # ğŸ¨ React UI Components for Obsidian
    â”‚   â”œâ”€â”€ NotebookLocalView.tsx   # Main tabbed interface (Obsidian view)
    â”‚   â”œâ”€â”€ FileManagerView.tsx     # File tree & processing controls
    â”‚   â”œâ”€â”€ EnhancedChatInput.tsx   # Natural language input
    â”‚   â””â”€â”€ IntentIndicator.tsx     # Real-time intent feedback
    â”œâ”€â”€ src/api/                    # ğŸ”— API Client Layer
    â”‚   â””â”€â”€ ApiClient-clean.ts      # HTTP client with 14+ endpoints
    â”œâ”€â”€ src/settings/               # âš™ï¸  Plugin Configuration Management
    â”‚   â””â”€â”€ model-clean.ts          # Settings & state management
    â””â”€â”€ main.ts                     # Obsidian Plugin Entry Point
```

### ğŸ›ï¸ **Service Design Philosophy**

**1. Separation of Concerns**
- **Backend Service**: Pure intelligence processing, document workflows, data management
- **Obsidian Plugin**: User experience, real-time UI, vault integration within Obsidian
- **Clear API Boundaries**: RESTful endpoints with comprehensive error handling

**2. Service-Oriented Architecture** 
- **Microservice-like Components**: Each service handles specific business logic
- **Event-driven Processing**: File changes trigger async document workflows
- **Horizontal Scalability**: Services can be independently scaled

**3. Modern Development Stack**
- **Backend**: FastAPI + PostgreSQL + LangGraph + Vector Search
- **Obsidian Plugin**: React + TypeScript + Tailwind CSS + Obsidian API
- **Infrastructure**: Docker-ready, environment-configurable

**4. Production-Ready Features**
- **Comprehensive Logging**: Full observability across all services
- **Error Handling**: Graceful degradation and recovery
- **Background Processing**: Non-blocking document workflows
- **Real-time Updates**: WebSocket-like experience through polling

## ğŸš€ Quick Start

### Prerequisites
- **Python 3.8+** with pip
- **Node.js 16+** with npm  
- **PostgreSQL 12+** 
- **Obsidian** with community plugins enabled

### Installation

1. **Clone and setup backend:**
```bash
git clone <repository-url>
cd 26th-summer-NotebookLocal/inference-server
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt

# Database setup
createdb notebooklocal
alembic upgrade head
```

2. **Configure environment:**
```bash
# Create .env file
cat > .env << EOF
DATABASE_URL=postgresql://user:password@localhost/notebooklocal
OPENAI_API_KEY=your-openai-key
MODEL_PROVIDER=openai
EOF
```

3. **Build and install plugin:**
```bash
cd ../notebook-local
npm install && npm run build
cp -r dist/* /path/to/vault/.obsidian/plugins/notebook-local/
```

4. **Start the system:**
```bash
# Start inference server
uvicorn src.main:app --host 0.0.0.0 --port 8000

# Enable plugin in Obsidian: Settings â†’ Community plugins â†’ "NotebookLocal"
```

## ğŸ¯ How to Use

### **1. Just Start Talking**
Open NotebookLocal in Obsidian and ask naturally:
```
What are the main themes in my research?
Find notes about machine learning from last week
Make this paragraph clearer
```

### **2. Use @Mentions for Precision**
```
@important.md What did I conclude here?
@research/ Summarize the key findings
@file1.md,file2.md,file3.md Compare these approaches
```

### **3. Let the System Learn Your Intent**
The system automatically detects what you want:
- Questions â†’ **UNDERSTAND** engine
- "Find" or "Show" â†’ **NAVIGATE** engine  
- "Make" or "Improve" â†’ **TRANSFORM** engine
- "Summarize" or "Compare" â†’ **SYNTHESIZE** engine
- "Check" or "Fix" â†’ **MAINTAIN** engine

## ğŸ“Š Technical Details

### **Context Pyramid System**
Files are ranked by relevance:
1. **Mentioned files** (@file.md) - Highest priority
2. **Current note** - High priority  
3. **Linked notes** - Medium-high priority
4. **Similar content** - Medium priority
5. **Recent files** - Temporal context
6. **Tagged content** - Shared topic context

### **API Endpoints**
- `POST /api/v1/intelligence/chat` - Main intelligence endpoint
- `GET /api/v1/intelligence/capabilities` - Available capabilities
- `POST /api/v1/intelligence/intent/detect` - Intent detection
- `POST /api/v1/vault/scan` - File processing

### **Database Integration**
- **PostgreSQL**: File metadata and processing status
- **Vector Store**: Semantic embeddings for content similarity
- **Real-time sync**: Obsidian file changes â†’ automatic processing

## ğŸ› Troubleshooting

**Plugin won't connect:**
- Verify inference server running on localhost:8000
- Check browser console for errors
- Test connection with the "Test Connection" button

**Files not found:**
- Ensure files are processed (Files tab shows status)
- Use exact file names in @mentions: `@filename.md`
- Check server logs for processing errors

**Responses seem off:**
- Verify current note path is detected correctly
- Try more specific @mentions to guide context
- Check Context tab to see what's included

## ğŸ”¬ Development

The system is built on **modular intelligence architecture**:

- **Easy capability expansion**: Add new engines for specific use cases
- **Context-aware processing**: Each capability gets optimized context
- **Natural language interface**: No command memorization needed
- **Precise control**: @mentions for when you need specificity

**Adding new capabilities:**
1. Create new engine in `inference-server/src/intelligence/engines/`
2. Add intent patterns to `intent_detector.py`
3. Register in `capability_router.py`

---

**ğŸ“ Built for intelligent knowledge work**
- Context-aware responses using your vault as ground truth
- Natural conversation enhanced by precise @mentions when needed
- Automatic intent detection and routing to specialized engines
- Real-time file processing with PostgreSQL + vector storage integration

For detailed setup: [ğŸ“¡ Server README](./inference-server/README.md) â€¢ [ğŸ“ Plugin README](./notebook-local/README.md)