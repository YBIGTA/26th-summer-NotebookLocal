# NotebookLocal Inference Server

A hybrid PostgreSQL + Weaviate RAG system with modular LLM routing and local model support.

## ğŸš€ Features

- **ğŸ—„ï¸ Hybrid Database**: PostgreSQL metadata + Weaviate vectors
- **ğŸ” Hybrid Search**: BM25 + semantic search with metadata filtering  
- **ğŸ¤– Modular LLM**: OpenAI, Anthropic, and local model support
- **âš¡ VLLM Ready**: Optimized for local model inference
- **ğŸ‡°ğŸ‡· Korean PDFs**: Advanced PyMuPDF integration
- **ğŸ³ Docker Setup**: One-command deployment

## ğŸ“¦ Quick Start

```bash
# 1. Run unified setup (installs UV, starts Docker, installs dependencies)
./setup_local_dev.sh

# 2. Configure API keys
nano .env  # Add your OPENAI_API_KEY

# 3. Start server
python start_server.py
```

## ğŸ”Œ API Endpoints

- **Docs**: http://localhost:8000/docs
- **Process PDF**: `POST /api/v1/process`
- **Ask Question**: `POST /api/v1/ask`
- **Obsidian Chat**: `POST /api/v1/obsidian/chat`
- **Search**: `POST /api/v1/obsidian/search`

## ğŸ› ï¸ Local Model Development

```bash
# Add VLLM for local inference
uv add vllm

# Add specific models
uv add transformers accelerate bitsandbytes

# Development setup
./setup_local_dev.sh
```

## ğŸ—ï¸ Architecture

```
PostgreSQL (metadata) â†â†’ Weaviate (vectors)
       â†“                     â†“
   Documents               Embeddings
   Chunks                 Hybrid Search
   Tags, Citations        BM25 + Semantic
```

## ğŸ“‚ Project Structure

```
inference-server/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ database/           # PostgreSQL models
â”‚   â”œâ”€â”€ storage/           # Hybrid storage coordinator  
â”‚   â”œâ”€â”€ workflows/         # Document & QA workflows
â”‚   â”œâ”€â”€ processors/        # PDF, text, embeddings
â”‚   â””â”€â”€ llm/              # Modular LLM routing
â”œâ”€â”€ api/                  # FastAPI routes
â”œâ”€â”€ docker-compose.yml    # Database setup
â””â”€â”€ pyproject.toml       # UV dependencies
```

## ğŸ”§ Configuration

Edit `.env` file:
```bash
DATABASE_URL=postgresql://inference_user:password@localhost:5432/inference_db
WEAVIATE_URL=http://localhost:8080
OPENAI_API_KEY=your_key_here
```

## ğŸ©º Troubleshooting

```bash
# Check services
docker-compose ps

# View logs  
docker-compose logs

# Test connections
curl http://localhost:8080/v1/.well-known/live  # Weaviate
psql $DATABASE_URL -c "SELECT 1"               # PostgreSQL
```

For detailed setup instructions, see [QUICKSTART.md](QUICKSTART.md) and [DATABASE_SETUP.md](DATABASE_SETUP.md).