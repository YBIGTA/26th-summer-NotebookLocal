# NotebookLocal Inference Server

A comprehensive PDF processing and RAG system with hybrid storage, modular LLM routing, and advanced monitoring capabilities.

## ğŸš€ Features

- **ğŸ—„ï¸ Hybrid Storage**: PostgreSQL metadata + Weaviate vector database
- **ğŸ” Advanced Search**: BM25 + semantic search with metadata filtering  
- **ğŸ¤– Multi-LLM Support**: OpenAI, Anthropic, and local model routing
- **ğŸ“„ PDF Intelligence**: Dual text extraction (direct + AI vision)
- **ğŸ‡°ğŸ‡· Korean Support**: Advanced PyMuPDF integration for Korean PDFs
- **ğŸ“Š Unified Logging**: Comprehensive request/response monitoring
- **ğŸ³ Docker Ready**: One-command database deployment

## ğŸ“¦ Quick Start

```bash
# 1. Setup environment and databases
./setup_local_dev.sh

# 2. Configure environment
cp .env.example .env
# Edit .env with your API keys

# 3. Start server
python start_server.py
```

## ğŸ—ï¸ Architecture Overview

### PDF Processing Pipeline
```
PDF Input â†’ PDFProcessor â†’ ImageProcessor â†’ TextProcessor â†’ HybridStore
    â”‚            â”‚              â”‚              â”‚             â”‚
    â”‚         Direct Text   AI Vision Text  Chunking     PostgreSQL
    â”‚         Extraction    (OpenAI API)    Embedding     + Weaviate
    â”‚
    â””â”€â”€â”€ Images â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Insights**:
1. **Dual Text Extraction**: 
   - **PDFProcessor**: Direct text from PDF (fast, accurate for typed text)
   - **ImageProcessor**: AI vision extracts text from images/diagrams (slower, uses OpenAI API)

2. **Smart Duplicate Detection**: 
   - Automatically detects duplicate PDFs using MD5 checksum
   - Skips reprocessing identical files, even with different filenames
   - Saves processing time and storage space

## ğŸ“‚ Project Structure

```
inference-server/
â”œâ”€â”€ ğŸ”§ Configuration
â”‚   â”œâ”€â”€ config.py              # Central configuration
â”‚   â”œâ”€â”€ .env.example           # Environment template
â”‚   â””â”€â”€ configs/               # LLM adapter configs
â”‚
â”œâ”€â”€ ğŸ—„ï¸ Database Layer
â”‚   â”œâ”€â”€ src/database/          # PostgreSQL models & connection
â”‚   â””â”€â”€ docker-compose.yml     # PostgreSQL + Weaviate setup
â”‚
â”œâ”€â”€ ğŸ“Š Storage Layer
â”‚   â””â”€â”€ src/storage/
â”‚       â”œâ”€â”€ hybrid_store.py    # Coordinates PostgreSQL + Weaviate
â”‚       â””â”€â”€ vector_store.py    # Weaviate operations
â”‚
â”œâ”€â”€ âš™ï¸ Processing Layer
â”‚   â””â”€â”€ src/processors/
â”‚       â”œâ”€â”€ pdf_processor.py   # PDF text + image extraction
â”‚       â”œâ”€â”€ image_processor.py # AI vision text extraction (OpenAI)
â”‚       â”œâ”€â”€ text_processor.py  # Text chunking
â”‚       â””â”€â”€ embedder.py        # Vector embeddings
â”‚
â”œâ”€â”€ ğŸ”„ Workflow Layer
â”‚   â””â”€â”€ src/workflows/
â”‚       â”œâ”€â”€ document_workflow.py # PDF processing pipeline
â”‚       â””â”€â”€ qa_workflow.py       # Question answering
â”‚
â”œâ”€â”€ ğŸ¤– LLM Layer
â”‚   â””â”€â”€ src/llm/               # Modular LLM routing system
â”‚       â”œâ”€â”€ core/router.py     # Route to different models
â”‚       â””â”€â”€ adapters/          # OpenAI, Anthropic, local models
â”‚
â”œâ”€â”€ ğŸŒ API Layer
â”‚   â””â”€â”€ api/
â”‚       â”œâ”€â”€ main.py            # FastAPI app
â”‚       â””â”€â”€ routes.py          # All endpoints
â”‚
â”œâ”€â”€ ğŸ” Monitoring & Debug
â”‚   â”œâ”€â”€ src/utils/logger.py    # Unified logging system
â”‚   â””â”€â”€ tools/                 # Debug and inspection tools
â”‚
â””â”€â”€ ğŸ“š Documentation
    â”œâ”€â”€ README.md              # This file
    â”œâ”€â”€ QUICKSTART.md          # Setup guide
    â”œâ”€â”€ DATABASE_SETUP.md      # Database configuration
    â””â”€â”€ MONITORING_GUIDE.md    # Logging configuration
```

## âš¡ Key Features Explained

### ğŸ”„ Smart Duplicate Detection

The system automatically prevents reprocessing identical PDFs:

**How it works:**
1. **File Checksum**: Calculates MD5 hash of uploaded file content
2. **Database Lookup**: Checks if checksum exists in PostgreSQL
3. **Smart Response**: If found, returns existing document info instead of reprocessing

**Benefits:**
- âš¡ **Performance**: Avoids redundant processing (saves minutes per duplicate)
- ğŸ’¾ **Storage**: Prevents duplicate chunks and embeddings
- ğŸ” **Fast Detection**: Database index makes lookup milliseconds

**Example Response:**
```json
{
  "doc_uid": "12345678-1234-5678-9012-123456789abc",
  "status": "exists",
  "chunks": 25,
  "images": 3
}
```

**What triggers duplicate detection:**
- âœ… Same file uploaded twice
- âœ… Same file with different filename  
- âœ… Identical content from different sources
- âŒ Modified files (treated as new documents)

### ğŸ“„ Page-Aware Processing

New architecture processes PDFs page-by-page for better context:

1. **Page Division**: Each PDF page processed individually
2. **Image Integration**: AI descriptions merged into page text before chunking
3. **Context Preservation**: Chunks maintain page number metadata
4. **Better Search**: Semantic search can locate content by page

## ğŸ”Œ API Endpoints

### Core Endpoints
- **ğŸ“„ Process PDF**: `POST /api/v1/process` - Upload and process PDF files
- **â“ Ask Question**: `POST /api/v1/ask` - Query processed documents
- **ğŸ” Search**: `POST /api/v1/obsidian/search` - Semantic document search
- **ğŸ“Š Health Check**: `GET /api/v1/health` - System status

### Obsidian Plugin Integration
- **ğŸ’¬ Chat**: `POST /api/v1/obsidian/chat` - RAG-enhanced chat
- **ğŸ“‹ Documents**: `GET /api/v1/obsidian/documents` - List processed files
- **ğŸ—‘ï¸ Delete**: `DELETE /api/v1/obsidian/documents/{id}` - Remove documents

### Debug Endpoints
- **ğŸ©º Health Detail**: `GET /api/v1/debug/health-detailed` - Detailed system status
- **ğŸ“Š DB Stats**: `GET /api/v1/debug/db-stats` - Database statistics

## âš™ï¸ Configuration

### Environment Variables (.env)
```bash
# Database Configuration
DATABASE_URL=postgresql://inference_user:password@localhost:5432/inference_db
WEAVIATE_URL=http://localhost:8080

# API Keys
OPENAI_API_KEY=your_openai_key_here

# Logging Configuration (for debugging)
DEBUG_MODE=false
LOG_API_REQUESTS=false
LOG_DATABASE_OPS=false
LOG_PROCESSING_DETAILS=false
```

### Enable Debug Logging
```bash
# Enable detailed logging for troubleshooting
DEBUG_MODE=true
LOG_API_REQUESTS=true
LOG_DATABASE_OPS=true
LOG_PROCESSING_DETAILS=true
```

## ğŸ©º Troubleshooting

### Performance Issues
- **Slow PDF processing**: Check OpenAI API rate limits and image count
- **Long delays**: Enable debug logging to see which step is slow
- The ImageProcessor makes OpenAI Vision API calls for every image - this is often the bottleneck

### Database Issues
```bash
# Check database status
docker-compose ps

# View database logs
docker-compose logs postgres weaviate

# Test connections
python tools/db_inspect.py
```

### Common Issues
- **Database connection**: Ensure Docker containers are running
- **Korean text issues**: Verify PyMuPDF installation and font support
- **API rate limits**: Monitor OpenAI usage in debug logs

For detailed instructions, see [QUICKSTART.md](QUICKSTART.md), [DATABASE_SETUP.md](DATABASE_SETUP.md), and [MONITORING_GUIDE.md](MONITORING_GUIDE.md).