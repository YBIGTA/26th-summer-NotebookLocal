# OpenAI GPT-4o-mini model configuration
name: gpt-4o-mini
provider: openai
model_id: gpt-4o-mini

# Model capabilities
capabilities:
  chat: true
  vision: true
  streaming: true
  embeddings: false

# Model parameters
temperature: 0.7
max_tokens: 4096
top_p: 1.0
frequency_penalty: 0.0
presence_penalty: 0.0

# API settings
timeout: 60
max_retries: 2

# Context window
context_window: 128000

# Model description
description: "OpenAI's fast and cost-effective small model, supports vision"
use_cases: ["quick_responses", "vision_tasks", "fast_responses"]

# Workflow-specific configurations
workflows:
  qa_workflow:
    system_prompt: |
      You are a helpful AI assistant. Answer the question based only on the provided context.
      If the question is in Korean, respond in Korean.
      Be concise but comprehensive. If you cannot answer based on the context, say "I cannot find information about this in the provided context."
    parameters:
      temperature: 0.3  # Lower for more focused answers
      max_tokens: 1024  # Concise responses
      top_p: 0.9
      frequency_penalty: 0.1
      presence_penalty: 0.0
    retrieval:
      preferred_k: 4  # Number of chunks to retrieve
      context_strategy: "concise"  # How to format context
    post_processing:
      max_answer_length: 2000
      add_sources: true
      truncate_long_responses: true
  
  summarization_workflow:
    system_prompt: |
      You are an expert summarizer. Create a concise summary of the provided content.
      Maintain key information while being brief.
    parameters:
      temperature: 0.4
      max_tokens: 512
      top_p: 0.95
    
  embedding_workflow:
    # Not applicable for this model (no embedding capability)
    enabled: false