# Routing rules configuration - Based on actual model configs in configs/models/
rules:
  # Explicit model mappings - ONLY models that have config files
  explicit_models:
    # OpenAI models (configs/models/openai/)
    - models: [gpt-4o-mini, text-embedding-3-large]
      adapter: openai
    
    # Anthropic models (configs/models/anthropic/)
    - models: [claude-3-5-sonnet-20241022]
      adapter: anthropic
    
    # Qwen models (configs/models/qwen/)
    - models: [Qwen3-14B-Instruct-bnb-4bit, Qwen2.5-VL-7B-Instruct-unsloth-bnb-4bit, Qwen3-embedding-0.6B]
      adapter: qwen
  
  # Content-based routing - using only available models
  chat_default: gpt-4o-mini                    # Chat model we have config for
  vision_default: gpt-4o-mini                  # Vision model we have config for
  embedding_default: text-embedding-3-large   # Embedding model we have config for

# Intelligence system configuration - uses chat_default from rules
intelligence:
  # Use the default chat model for all intelligence operations
  use_chat_default: true
  
  # Engine-specific parameters (all use chat_default model)
  engines:
    understand:
      temperature: 0.3
      max_tokens: 1000
      
    navigate:
      temperature: 0.4
      max_tokens: 800
      
    transform:
      temperature: 0.3
      max_tokens: 1200
      
    synthesize:
      temperature: 0.2
      max_tokens: 1500
      
    maintain:
      temperature: 0.1
      max_tokens: 800

  # Context building configuration
  context:
    max_tokens: 8000
    token_limits:
      understand: 8000
      navigate: 9600    # 20% more for discovery
      transform: 4800   # 40% less, focus on current content  
      synthesize: 12000 # 50% more for pattern finding
      maintain: 6400    # 20% less for structural tasks

  # Intent detection configuration  
  intent_detection:
    confidence_threshold: 0.6
    use_llm_fallback: true
