# Routing rules configuration - Based on actual model configs in configs/models/
rules:
  # Explicit model mappings - ONLY models that have config files
  explicit_models:
    # OpenAI models (configs/models/openai/)
    - models: [gpt-4o-mini, text-embedding-3-large]
      adapter: openai
    
    # Anthropic models (configs/models/anthropic/)
    - models: [claude-3-5-sonnet-20241022]
      adapter: anthropic
    
    # Qwen models (configs/models/qwen/)
    - models: [Qwen3-14B-Instruct-bnb-4bit, Qwen2.5-VL-7B-Instruct-unsloth-bnb-4bit, Qwen3-embedding-0.6B]
      adapter: qwen
  
  # Content-based routing - using only available models
  chat_default: gpt-4o-mini                    # Chat model we have config for
  vision_default: gpt-4o-mini                  # Vision model we have config for
  embedding_default: text-embedding-3-large   # Embedding model we have config for

# Intelligence system configuration - uses chat_default from rules
intelligence:
  # Use the default chat model for all intelligence operations
  use_chat_default: true
  
  # Engine-specific parameters (all use chat_default model)
  engines:
    understand:
      temperature: 0.3
      
    navigate:
      temperature: 0.4
      
    transform:
      temperature: 0.3
      
    synthesize:
      temperature: 0.2
      
    maintain:
      temperature: 0.1

  # Dynamic token allocation based on model capabilities
  token_allocation:
    # Use percentage of model's context_window for context building
    context_window_ratio: 0.6  # Use 60% of model's context window
    
    # Engine ratios (percentages of allocated context)
    engine_ratios:
      understand: 0.15    # 15% - Simple comprehension
      navigate: 0.25      # 25% - Discovery and exploration
      transform: 0.10     # 10% - Focused code changes
      synthesize: 0.35    # 35% - Complex analysis and patterns
      maintain: 0.15      # 15% - Structural maintenance

  # Intent detection configuration  
  intent_detection:
    confidence_threshold: 0.6
    use_llm_fallback: true
